# Conversational Analytics Engine

A Safe, Explainable "Chat with Data" System

## Overview

This project is a conversational analytics engine that allows users to query business metrics using natural language while ensuring correctness, explainability, and trust.

Unlike typical "chat with data" demos, this system:

- âœ… Uses deterministic analytics logic for all calculations
- âœ… Uses LLMs only for intent classification and explanation phrasing
- âœ… Enforces causal reasoning via an explicit causal graph
- âœ… Never hallucinates metrics, numbers, or causes
- âœ… Gracefully handles missing or unsupported data

The result is a chatbot that behaves like a real BI analyst, not a guessing model.

## ğŸ¯ Core Capabilities

### âœ… Metric Queries

Ask for the value of a metric at a specific time.

**Examples:**
- "What was revenue yesterday?"
- "How was conversion rate day before yesterday?"

### âœ… Comparisons (Point-in-Time)

Compare a metric across two specific periods.

**Examples:**
- "Compare traffic today vs yesterday"
- "Compare revenue yesterday vs day before"

### âœ… Trend Analysis

Analyze how a metric changes over time.

**Examples:**
- "Show revenue trend last 7 days"
- "How has traffic changed over time?"

### âœ… Performance Summaries

Get an executive-level summary across multiple KPIs.

**Examples:**
- "Give me a summary for today"
- "How did we perform yesterday?"
- "How did we perform last week?"

**Supports:**
- Daily summaries (day-over-day)
- Weekly aggregated summaries (explicit aggregation rules)

### âœ… Root Cause Analysis (Daily)

Explain why a metric changed on a specific day.

**Examples:**
- "Why did revenue drop yesterday?"
- "Why did traffic spike today?"

**Uses:**
- Deterministic metric deltas
- Directional alignment
- Causal graph constraints
- LLM only for narrative explanation

### âœ… Root Cause Analysis (Weekly / Aggregated)

Explain why an entire period (e.g. last week) performed worse.

**Examples:**
- "Why did last week perform worse?"
- "What went wrong last week?"

This is implemented as a hybrid flow:
- Weekly aggregation (deterministic)
- Week-over-week comparison
- Identification of top negative contributors
- Causal explanation using the same safe pipeline

## ğŸ§  Design Philosophy

### Deterministic First, LLM Last

| Component | Responsibility |
|-----------|---------------|
| Data Store | Source of truth |
| Query Planner | Deterministic execution plan |
| Aggregation Logic | Explicit math rules |
| Causal Graph | Allowed causal paths |
| LLM | Language only (no math, no guessing) |

**LLMs never:**
- âŒ Compute numbers
- âŒ Query data
- âŒ Decide causality
- âŒ Invent metrics

## ğŸ—ï¸ Architecture

```
User Question
     â†“
Intent Classifier (LLM, constrained)
     â†“
Query Planner (deterministic)
     â†“
Data Store (Pandas / CSV)
     â†“
Aggregation & Comparison Logic
     â†“
Causal Reasoning (Graph-constrained)
     â†“
LLM (Explanation phrasing only)
     â†“
Final Answer
```

## ğŸ“ Project Structure

```
dashboard-chatbot/
â”‚
â”œâ”€â”€ chatbot.py              # CLI entry point
â”œâ”€â”€ intent_classifier.py    # Intent detection (LLM, constrained)
â”œâ”€â”€ query_planner.py        # Deterministic query planning
â”œâ”€â”€ data_store.py           # Pandas-backed metrics store
â”œâ”€â”€ response_builder.py     # Core business logic + explanations
â”œâ”€â”€ threshold_event.py      # Event model for root cause analysis
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ metrics.csv         # Example dataset
â”‚
â”œâ”€â”€ causal_graph.yaml       # Explicit causal relationships
â”‚
â”œâ”€â”€ llm/
â”‚   â””â”€â”€ ollama_client.py    # LLM interface (timeout-safe)
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ context_builder.py  # Builds context for explanations
â”‚   â”œâ”€â”€ explainer.py       # LLM explanation generation
â”‚   â”œâ”€â”€ fallback.py        # Fallback explanations
â”‚   â””â”€â”€ prompt.py          # LLM prompt guardrails
â”‚
â””â”€â”€ README.md
```

## ğŸ“Š Dataset Expectations

The system expects a tabular dataset with:

- A `date` column (ISO format: YYYY-MM-DD)
- One column per metric

**Example:**

```csv
date,Revenue,Traffic,Conversion Rate,Orders
2024-09-25,113200,44800,2.68,1201
2024-09-26,114600,45200,2.7,1220
...
```

**Supported Metrics:**
- Revenue
- Traffic
- Conversion Rate
- Orders
- Average Order Value

## ğŸ”— Causal Graph

Causality is explicitly defined in `causal_graph.yaml`. The LLM cannot reference causes outside this graph.

**Example:**

```yaml
Revenue:
  causes:
    - Average Revenue Per User
    - Activated Users
```

This ensures that root cause explanations are grounded in predefined relationships, preventing hallucination.

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- [Ollama](https://ollama.ai/) installed and running locally
- Mistral 7B model (or compatible model) available in Ollama

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd "dashboard chatbot"
```

2. Install dependencies:
```bash
pip install pandas requests pyyaml
```

3. Ensure Ollama is running:
```bash
ollama serve
```

4. Pull the required model (if not already available):
```bash
ollama pull mistral:7b-instruct
```

### Running the Chatbot

```bash
python chatbot.py
```

**Example session:**

```
You: show revenue trend last 7 days
Bot: Revenue shows a downward trend over the last 7 days with a change of 26.5%.

You: why did last week perform worse?
Bot: Last week's performance declined primarily due to a drop in Revenue...
```

## ğŸ›¡ï¸ Safety & Guardrails

This system explicitly prevents:

- âŒ Metric hallucination
- âŒ Silent aggregation assumptions
- âŒ Causal overclaiming
- âŒ LLM-driven calculations
- âŒ Unsupported period guessing

If a query cannot be answered safely, the chatbot refuses gracefully.

## ğŸš€ Why This Is Different

**Most "chat with data" tools:**
- Let the LLM guess
- Mix reasoning and math
- Hallucinate causes
- Break silently on edge cases

**This system:**
- Treats analytics as engineering, not prompting
- Makes all assumptions explicit
- Is auditable, debuggable, and extensible

## ğŸ”® Future Extensions

- Conversational memory (safe follow-ups)
- Monthly / custom range summaries
- Visualizations + chat
- Slack / Web deployment
- Confidence scoring per explanation

## ğŸ Summary

This project demonstrates how to build a trustworthy conversational analytics system by combining:

- Deterministic data pipelines
- Explicit causal reasoning
- Carefully constrained LLM usage

It is designed to scale from a local CLI to production BI environments without sacrificing correctness.

## ğŸ“ License

[Add your license information here]

## ğŸ¤ Contributing

[Add contribution guidelines here]